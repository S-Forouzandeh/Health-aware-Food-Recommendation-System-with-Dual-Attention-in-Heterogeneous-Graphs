2023-09-29 20:52:24,967: This is an informational log message.
Number of unique user_ids: 70390
Number of unique recipe_ids: 46702
Number of interactions between users and recipes: 231637
Number of unique ingredients: 230475
2023-09-29 20:52:29,486: Loading data into a graph...
2023-09-29 20:52:44,939: Finished; resulting graph:
2023-09-29 20:52:44,939: Graph with 132041 nodes and 1987779 edges
2023-09-29 20:58:33,092: Loading data into a graph...
2023-09-29 20:58:48,093: Finished; resulting graph:
2023-09-29 20:58:48,094: Graph with 132041 nodes and 1987779 edges
2023-09-29 21:05:15,063: Epoch 1/10, NLA Loss: 13.3408
2023-09-29 21:11:35,499: Epoch 2/10, NLA Loss: 7.2598
2023-09-29 21:18:04,818: Epoch 3/10, NLA Loss: 5.2213
2023-09-29 21:24:35,837: Epoch 4/10, NLA Loss: 4.0946
2023-09-29 21:31:09,273: Epoch 5/10, NLA Loss: 3.3513
2023-09-29 21:37:42,538: Epoch 6/10, NLA Loss: 2.8142
2023-09-29 21:44:14,683: Epoch 7/10, NLA Loss: 2.4036
2023-09-29 21:50:46,477: Epoch 8/10, NLA Loss: 2.0811
2023-09-29 21:57:18,804: Epoch 9/10, NLA Loss: 1.8216
2023-09-29 22:03:49,239: Epoch 10/10, NLA Loss: 1.6103
2023-09-29 22:03:51,154: Embedding Vectors (NLA):
2023-09-29 22:03:51,154: tensor([[ 5.0000,  5.0000,  5.0000,  ...,  5.0000,  5.0000,  5.0000],
        [ 4.3460,  4.3460,  4.3460,  ...,  4.3460,  4.3460,  4.3460],
        [ 4.3219,  4.3218,  4.3219,  ...,  4.3219,  4.3219,  4.3219],
        ...,
        [ 0.1611, -0.2398,  0.2473,  ..., -0.2158,  0.1185, -0.2288],
        [ 2.5805,  2.9542,  3.7405,  ...,  1.7438,  4.3551,  2.5298],
        [ 2.5854,  3.1322,  3.2032,  ...,  3.0941,  2.7420,  2.9336]])
2023-09-29 22:03:52,965: Epoch SLA 1/10, SLA Loss: 0.7638
2023-09-29 22:03:53,891: Epoch SLA 2/10, SLA Loss: 0.7632
2023-09-29 22:03:54,820: Epoch SLA 3/10, SLA Loss: 0.7626
2023-09-29 22:03:55,751: Epoch SLA 4/10, SLA Loss: 0.7620
2023-09-29 22:03:56,676: Epoch SLA 5/10, SLA Loss: 0.7614
2023-09-29 22:03:57,602: Epoch SLA 6/10, SLA Loss: 0.7608
2023-09-29 22:03:58,525: Epoch SLA 7/10, SLA Loss: 0.7602
2023-09-29 22:03:59,452: Epoch SLA 8/10, SLA Loss: 0.7596
2023-09-29 22:04:00,381: Epoch SLA 9/10, SLA Loss: 0.7590
2023-09-29 22:04:01,313: Epoch SLA 10/10, SLA Loss: 0.7583
2023-09-29 22:04:01,313: Embeddings Vectors (SLA) based Healthy recipes:
2023-09-29 22:04:01,313: tensor([[-0.2220,  0.1260,  0.6052,  ..., -0.2388,  1.4362, -0.5965],
        [-0.6896, -0.1098, -0.7429,  ...,  0.7687, -0.0327, -0.0334],
        [-0.5605,  0.1770,  1.1057,  ...,  0.5610, -0.6970, -0.6776],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       grad_fn=<CatBackward0>)
Results for Different Values of Library Metris based k:
=======================================================
k    Mean Precision      Mean Recall         Mean F1-score       
=======================================================
1    0.0555     0.0555     0.0555
2    0.0520     0.1012     0.0684
3    0.0505     0.1446     0.0744
4    0.0503     0.1865     0.0785
5    0.0513     0.2316     0.0830
6    0.0516     0.2740     0.0859
7    0.0518     0.3133     0.0877
8    0.0520     0.3513     0.0894
9    0.0524     0.3871     0.0910
10   0.0526     0.4204     0.0922
=====================================
Mean AUC Score: 0.4995
=====================================

================================================================================
                     Resource Usage on 30/09/2023 01:37:32                      

Job Id: 4871681 
Queue: MATHS
Walltime: 04:45:11  (requested 24:00:00)
Job execution was successful. Exit Status 0. 

--------------------------------------------------------------------------------
|              |             CPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node         | Requested   Used   Efficiency | Requested   Used   Efficiency |
| k150         |    16       4.39      27.0%   |  128.0gb   38.69gb    30.2%   |
--------------------------------------------------------------------------------
